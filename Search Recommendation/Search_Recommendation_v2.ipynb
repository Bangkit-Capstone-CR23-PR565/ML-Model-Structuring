{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# events_df = pd.read_csv(\"https://api.mockaroo.com/api/3f045400?count=1000&key=9aadb790\")\n",
    "events_df = pd.read_csv(\"events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "data = list(map(lambda x: ast.literal_eval(x), events_df['tags']))\n",
    "data_set = []\n",
    "for row in data:\n",
    "    data_set += row\n",
    "data_set = set(data_set)\n",
    "data = list(map(lambda x: ', '.join(x), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_random_tag(set: data_set):\n",
    "    return list(data_set)[random.randint(0,len(data_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_chars():\n",
    "    # Exclude unnecessary characters\n",
    "    exclude_chars = '\\{\\}[]\\'\\\"'\n",
    "    data = [x.translate(str.maketrans('','',exclude_chars)) for x in data]\n",
    "    query = query.translate(str.maketrans('','',exclude_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Function to get the top n recommendations for a given document index\n",
    "def get_recommendations_tfidf(query, data, top_n=1, output_mode='tf_idf'):\n",
    "    # Create the TextVectorization layer\n",
    "    vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "        max_tokens=None,  # Default value, no maximum limit on vocabulary size\n",
    "        output_mode=output_mode,\n",
    "        output_sequence_length=None,  # Default value, variable length sequences\n",
    "        pad_to_max_tokens=False,  # Don't pad sequences\n",
    "        standardize='lower_and_strip_punctuation',  # Disable standardization\n",
    "        split='whitespace',  # Split text by whitespace\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data\n",
    "    new_data = data + [query]\n",
    "    # print(new_data)\n",
    "    vectorizer.adapt(new_data)\n",
    "    X = vectorizer(new_data)\n",
    "\n",
    "    # Compute the pairwise cosine similarity\n",
    "    cosine_sim = tf.linalg.matmul(X, X, transpose_b=True)\n",
    "\n",
    "    # Get the pairwise cosine similarity scores for the document\n",
    "    sim_scores = list(enumerate(cosine_sim[-1, :-1]))\n",
    "\n",
    "    # Sort the documents by similarity score in descending order\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top n recommendations\n",
    "    top_docs = sim_scores[:top_n]\n",
    "    print(top_docs)\n",
    "\n",
    "    # Return the indices and recommendations\n",
    "    return [[new_data[i], i, float(j)] for i, j in top_docs]\n",
    "\n",
    "def loop_print(arr,contains):\n",
    "  for el in arr:\n",
    "    print(el)\n",
    "  print(len(set(i[0] for i in arr) & contains))\n",
    "  print()\n",
    "\n",
    "def check_contains(raw_string):\n",
    "    words = raw_string.strip(\"{},\").split()\n",
    "    output = {datum for datum in data if all(word in datum for word in words)}\n",
    "    \n",
    "    for i in output:\n",
    "        print(i)\n",
    "    print()\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building\n",
      "Conference, Building & Construction, IT & Technology\n",
      "Conference, Building & Construction, Environmental Engineering\n",
      "Tradeshow, Building & Construction, Furnishings & Decor, Bathroom & Kitchen, Flooring & Roofing\n",
      "Tradeshow, Building & Construction, Home & Office\n",
      "Conference, Building & Construction, Industrial Engineering\n",
      "Conference, Building & Construction\n",
      "Tradeshow, Building & Construction, Home & Office, Interior Design\n",
      "Tradeshow, Building & Construction\n",
      "Conference, Building & Construction, Civil Engineering\n",
      "\n",
      "[(1, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>), (17, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>), (56, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>), (101, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>), (145, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>), (153, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>), (200, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>), (207, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>), (236, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>), (245, <tf.Tensor: shape=(), dtype=float32, numpy=11.48682>)]\n",
      "['Tradeshow, Building & Construction', 1, 11.486820220947266]\n",
      "['Tradeshow, Building & Construction, Home & Office, Interior Design', 17, 11.486820220947266]\n",
      "['Tradeshow, Building & Construction, Home & Office', 56, 11.486820220947266]\n",
      "['Conference, Building & Construction, Industrial Engineering', 101, 11.486820220947266]\n",
      "['Tradeshow, Building & Construction, Home & Office', 145, 11.486820220947266]\n",
      "['Conference, Building & Construction', 153, 11.486820220947266]\n",
      "['Conference, Building & Construction, Civil Engineering', 200, 11.486820220947266]\n",
      "['Tradeshow, Building & Construction', 207, 11.486820220947266]\n",
      "['Conference, Building & Construction, IT & Technology', 236, 11.486820220947266]\n",
      "['Tradeshow, Building & Construction, Furnishings & Decor, Bathroom & Kitchen, Flooring & Roofing', 245, 11.486820220947266]\n",
      "8\n",
      "\n",
      "[(100, <tf.Tensor: shape=(), dtype=int64, numpy=744>), (128, <tf.Tensor: shape=(), dtype=int64, numpy=744>), (134, <tf.Tensor: shape=(), dtype=int64, numpy=744>), (159, <tf.Tensor: shape=(), dtype=int64, numpy=744>), (165, <tf.Tensor: shape=(), dtype=int64, numpy=744>), (174, <tf.Tensor: shape=(), dtype=int64, numpy=744>), (181, <tf.Tensor: shape=(), dtype=int64, numpy=744>), (192, <tf.Tensor: shape=(), dtype=int64, numpy=744>), (280, <tf.Tensor: shape=(), dtype=int64, numpy=744>), (282, <tf.Tensor: shape=(), dtype=int64, numpy=744>)]\n",
      "['Workshop, Education & Training, Banking & Finance, Investment', 100, 744.0]\n",
      "['Workshop, Education & Training, Banking & Finance, Risk Management', 128, 744.0]\n",
      "['Workshop, Renewable Energy, Power & Energy, Banking & Finance', 134, 744.0]\n",
      "['Workshop, Miscellaneous', 159, 744.0]\n",
      "['Workshop, Medical & Pharma, Education & Training, Paid entry', 165, 744.0]\n",
      "['Workshop, Education & Training, Banking & Finance, Fundraising', 174, 744.0]\n",
      "['Workshop, Medical & Pharma, Education & Training, Paid entry', 181, 744.0]\n",
      "['Workshop, Education & Training, Banking & Finance', 192, 744.0]\n",
      "['Workshop, Education & Training, Banking & Finance', 280, 744.0]\n",
      "['Workshop, Education & Training, Banking & Finance', 282, 744.0]\n",
      "0\n",
      "\n",
      "[(1, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (17, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (56, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (101, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (145, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (153, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (200, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (207, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (236, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (245, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)]\n",
      "['Tradeshow, Building & Construction', 1, 1.0]\n",
      "['Tradeshow, Building & Construction, Home & Office, Interior Design', 17, 1.0]\n",
      "['Tradeshow, Building & Construction, Home & Office', 56, 1.0]\n",
      "['Conference, Building & Construction, Industrial Engineering', 101, 1.0]\n",
      "['Tradeshow, Building & Construction, Home & Office', 145, 1.0]\n",
      "['Conference, Building & Construction', 153, 1.0]\n",
      "['Conference, Building & Construction, Civil Engineering', 200, 1.0]\n",
      "['Tradeshow, Building & Construction', 207, 1.0]\n",
      "['Conference, Building & Construction, IT & Technology', 236, 1.0]\n",
      "['Tradeshow, Building & Construction, Furnishings & Decor, Bathroom & Kitchen, Flooring & Roofing', 245, 1.0]\n",
      "8\n",
      "\n",
      "[(1, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (17, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (56, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (101, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (145, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (153, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (200, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (207, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (236, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (245, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)]\n",
      "['Tradeshow, Building & Construction', 1, 1.0]\n",
      "['Tradeshow, Building & Construction, Home & Office, Interior Design', 17, 1.0]\n",
      "['Tradeshow, Building & Construction, Home & Office', 56, 1.0]\n",
      "['Conference, Building & Construction, Industrial Engineering', 101, 1.0]\n",
      "['Tradeshow, Building & Construction, Home & Office', 145, 1.0]\n",
      "['Conference, Building & Construction', 153, 1.0]\n",
      "['Conference, Building & Construction, Civil Engineering', 200, 1.0]\n",
      "['Tradeshow, Building & Construction', 207, 1.0]\n",
      "['Conference, Building & Construction, IT & Technology', 236, 1.0]\n",
      "['Tradeshow, Building & Construction, Furnishings & Decor, Bathroom & Kitchen, Flooring & Roofing', 245, 1.0]\n",
      "8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = ', '.join([get_random_tag(data_set) for i in range(3)])\n",
    "query = \"Building\"\n",
    "print(query)\n",
    "\n",
    "output = check_contains(query)\n",
    "\n",
    "recs = get_recommendations_tfidf(query, data, top_n=10)\n",
    "loop_print(recs, output)\n",
    "recs = get_recommendations_tfidf(query, data, top_n=10, output_mode='int')\n",
    "loop_print(recs, output)\n",
    "recs = get_recommendations_tfidf(query, data, top_n=10, output_mode='count')\n",
    "loop_print(recs, output)\n",
    "recs = get_recommendations_tfidf(query, data, top_n=10, output_mode='multi_hot')\n",
    "loop_print(recs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (1, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (3, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (4, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (5, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (6, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (7, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (10, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (16, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>), (17, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)]\n",
      "[1]\n",
      "[2, 208]\n",
      "[4, 30, 116, 234]\n",
      "[5, 180]\n",
      "[6, 165, 238]\n",
      "[7, 98, 187, 324]\n",
      "[8, 247]\n",
      "[11]\n",
      "[]\n",
      "[18]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'event_id': 1,\n",
       "  'event_name': 'Tyre & Rubber Indonesia',\n",
       "  'tags': 'Tradeshow, Auto & Automotive, Rubber & Tyres',\n",
       "  'match_score': 1.0},\n",
       " 1: {'event_id': 2,\n",
       "  'event_name': 'Indonesia International Construction, Infrastructure & Mining Exhibition (CON-MINE)',\n",
       "  'tags': 'Tradeshow, Building & Construction',\n",
       "  'match_score': 1.0},\n",
       " 2: {'event_id': 208,\n",
       "  'event_name': 'International Flooring Technology (IFT)',\n",
       "  'tags': 'Tradeshow, Building & Construction',\n",
       "  'match_score': 1.0},\n",
       " 3: {'event_id': 4,\n",
       "  'event_name': 'World AI Show - Jakarta (WAIS)',\n",
       "  'tags': 'Tradeshow, IT & Technology',\n",
       "  'match_score': 1.0},\n",
       " 4: {'event_id': 30,\n",
       "  'event_name': 'Lazada Run Indonesia',\n",
       "  'tags': 'Tradeshow, IT & Technology',\n",
       "  'match_score': 1.0},\n",
       " 5: {'event_id': 116,\n",
       "  'event_name': 'Digital Transformation Indonesia Conference and Expo (DTI-CX)',\n",
       "  'tags': 'Tradeshow, IT & Technology',\n",
       "  'match_score': 1.0},\n",
       " 6: {'event_id': 234,\n",
       "  'event_name': 'Smart IoT Indonesia',\n",
       "  'tags': 'Tradeshow, IT & Technology',\n",
       "  'match_score': 1.0},\n",
       " 7: {'event_id': 5,\n",
       "  'event_name': 'Bali & Beyond Travel Fair (BBTF)',\n",
       "  'tags': 'Tradeshow, Travel & Tourism',\n",
       "  'match_score': 1.0},\n",
       " 8: {'event_id': 180,\n",
       "  'event_name': 'Mummy n Me',\n",
       "  'tags': 'Tradeshow, Travel & Tourism',\n",
       "  'match_score': 1.0},\n",
       " 9: {'event_id': 6,\n",
       "  'event_name': 'Indonesia International Consumer Electronics Exhibition (IICEE)',\n",
       "  'tags': 'Tradeshow, Electric & Electronics',\n",
       "  'match_score': 1.0}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recommendations_tfidf(query, data, top_n=1, output_mode='tf_idf'):\n",
    "    # Create the TextVectorization layer\n",
    "    vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "        max_tokens=None,  # Default value, no maximum limit on vocabulary size\n",
    "        output_mode=output_mode,\n",
    "        output_sequence_length=None,  # Default value, variable length sequences\n",
    "        pad_to_max_tokens=False,  # Don't pad sequences\n",
    "        standardize='lower_and_strip_punctuation',  # Disable standardization\n",
    "        split='whitespace',  # Split text by whitespace\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data\n",
    "    new_data = data + [query]\n",
    "    # print(new_data)\n",
    "    vectorizer.adapt(new_data)\n",
    "    X = vectorizer(new_data)\n",
    "\n",
    "    # Compute the pairwise cosine similarity\n",
    "    cosine_sim = tf.linalg.matmul(X, X, transpose_b=True)\n",
    "\n",
    "    # Get the pairwise cosine similarity scores for the document\n",
    "    sim_scores = list(enumerate(cosine_sim[-1, :-1]))\n",
    "\n",
    "    # Sort the documents by similarity score in descending order\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top n recommendations\n",
    "    top_docs = sim_scores[:top_n]\n",
    "    print(top_docs)\n",
    "    # Return the indices and recommendations\n",
    "    output = {}\n",
    "    c=0\n",
    "    for i, j in top_docs:\n",
    "        tags = new_data[i]\n",
    "        match_score = float(j)\n",
    "\n",
    "        tags_str = str(tags.split(', '))\n",
    "        events_with_tags_df = events_df[events_df['tags']==tags_str]\n",
    "        ids = list(events_with_tags_df['id'])\n",
    "        print(ids)\n",
    "        event_names = list(events_with_tags_df['event_name'])\n",
    "        for index in range(len(events_with_tags_df)):\n",
    "            if c == 10:\n",
    "                break\n",
    "            output[c] = {\n",
    "                'event_id': ids[index],\n",
    "                'event_name': event_names[index],\n",
    "                'tags': tags,\n",
    "                'match_score': match_score\n",
    "            }\n",
    "            c += 1\n",
    "    return output\n",
    "output = get_recommendations_tfidf(\"Tradeshow\", data, top_n=10, output_mode='multi_hot')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m top_docs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_docs' is not defined"
     ]
    }
   ],
   "source": [
    "top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m matched_events \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m----> 2\u001b[0m matched_tags \u001b[39m=\u001b[39m \u001b[39mset\u001b[39;49m(j[\u001b[39m'\u001b[39;49m\u001b[39mevent_name\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m i,j \u001b[39min\u001b[39;49;00m output\u001b[39m.\u001b[39;49mitems())\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m matched_tags:\n\u001b[0;32m      4\u001b[0m     output_str \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(tag\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "matched_events = set()\n",
    "matched_tags = set(j['event_name'] for i,j in output.items())\n",
    "for tag in matched_tags:\n",
    "    output_str = str(tag.split(', '))\n",
    "    print(list(events_df[events_df['tags']==output_str]['event_name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
